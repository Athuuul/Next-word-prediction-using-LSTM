{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1483651,"sourceType":"datasetVersion","datasetId":870709},{"sourceId":4032467,"sourceType":"datasetVersion","datasetId":2389252},{"sourceId":12873234,"sourceType":"datasetVersion","datasetId":8143439}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam\nimport pickle\nimport numpy as np\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-26T10:54:29.909092Z","iopub.execute_input":"2025-08-26T10:54:29.909568Z","iopub.status.idle":"2025-08-26T10:54:29.913574Z","shell.execute_reply.started":"2025-08-26T10:54:29.909543Z","shell.execute_reply":"2025-08-26T10:54:29.912901Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"file = open(\"/kaggle/input/next-word-prediction/1661-0.txt\", \"r\", encoding=\"utf8\")\ndata = file.read()\ndata = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')\ndata = ' '.join(data.split())\nprint(data[:500])\nprint(len(data))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-26T10:54:32.099043Z","iopub.execute_input":"2025-08-26T10:54:32.099301Z","iopub.status.idle":"2025-08-26T10:54:32.123044Z","shell.execute_reply.started":"2025-08-26T10:54:32.099282Z","shell.execute_reply":"2025-08-26T10:54:32.122484Z"}},"outputs":[{"name":"stdout","text":"Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan DoyleThis eBook is for the use of anyone anywhere at no cost and withalmost no restrictions whatsoever. You may copy it, give it away orre-use it under the terms of the Project Gutenberg License includedwith this eBook or online at www.gutenberg.netTitle: The Adventures of Sherlock HolmesAuthor: Arthur Conan DoyleRelease Date: November 29, 2002 [EBook #1661]Last Updated: May 20, 2019Language: EnglishCharacter set encoding: UT\n564156\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts([data])\npickle.dump(tokenizer, open('token.pkl', 'wb'))\nsequence_data = tokenizer.texts_to_sequences([data])[0]\nprint(sequence_data[:15])\nprint(len(sequence_data))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T10:54:33.970765Z","iopub.execute_input":"2025-08-26T10:54:33.971034Z","iopub.status.idle":"2025-08-26T10:54:34.153279Z","shell.execute_reply.started":"2025-08-26T10:54:33.971016Z","shell.execute_reply":"2025-08-26T10:54:34.152688Z"}},"outputs":[{"name":"stdout","text":"[159, 4841, 1, 956, 5, 122, 32, 44, 548, 2007, 4842, 1035, 13, 21, 1]\n102507\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"vocab_size = len(tokenizer.word_index) + 1\nprint(vocab_size)\nsequences = []\n\nfor i in range(3, len(sequence_data)):\n    words = sequence_data[i-3:i+1]\n    sequences.append(words)\n    \nprint(\"The Length of sequences are: \", len(sequences))\nsequences = np.array(sequences)\nprint(sequences[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T10:54:36.127934Z","iopub.execute_input":"2025-08-26T10:54:36.128190Z","iopub.status.idle":"2025-08-26T10:54:36.211194Z","shell.execute_reply.started":"2025-08-26T10:54:36.128171Z","shell.execute_reply":"2025-08-26T10:54:36.210611Z"}},"outputs":[{"name":"stdout","text":"13136\nThe Length of sequences are:  102504\n[[ 159 4841    1  956]\n [4841    1  956    5]\n [   1  956    5  122]\n [ 956    5  122   32]\n [   5  122   32   44]\n [ 122   32   44  548]\n [  32   44  548 2007]\n [  44  548 2007 4842]\n [ 548 2007 4842 1035]\n [2007 4842 1035   13]]\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"X = []\ny = []\n\nfor i in sequences:\n    X.append(i[0:3])\n    y.append(i[3])\n    \nX = np.array(X)\ny = np.array(y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T10:54:38.489787Z","iopub.execute_input":"2025-08-26T10:54:38.490066Z","iopub.status.idle":"2025-08-26T10:54:38.592466Z","shell.execute_reply.started":"2025-08-26T10:54:38.490047Z","shell.execute_reply":"2025-08-26T10:54:38.591949Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"print(\"Data: \", X[:10])\nprint(\"Response: \", y[:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T10:54:43.556324Z","iopub.execute_input":"2025-08-26T10:54:43.556736Z","iopub.status.idle":"2025-08-26T10:54:43.562571Z","shell.execute_reply.started":"2025-08-26T10:54:43.556704Z","shell.execute_reply":"2025-08-26T10:54:43.561766Z"}},"outputs":[{"name":"stdout","text":"Data:  [[ 159 4841    1]\n [4841    1  956]\n [   1  956    5]\n [ 956    5  122]\n [   5  122   32]\n [ 122   32   44]\n [  32   44  548]\n [  44  548 2007]\n [ 548 2007 4842]\n [2007 4842 1035]]\nResponse:  [ 956    5  122   32   44  548 2007 4842 1035   13]\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"y = to_categorical(y, num_classes=vocab_size)\ny[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T10:54:46.175153Z","iopub.execute_input":"2025-08-26T10:54:46.175467Z","iopub.status.idle":"2025-08-26T10:54:46.464119Z","shell.execute_reply.started":"2025-08-26T10:54:46.175429Z","shell.execute_reply":"2025-08-26T10:54:46.463562Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"embedding_index = {}\nglove_file = '/kaggle/input/glove-embeddings/glove.6B.100d.txt'  # path to your GloVe file\n\nwith open(glove_file, 'r', encoding='utf8') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embedding_index[word] = coefs\n\nprint(\"Loaded GloVe word vectors:\", len(embedding_index))\n\nembedding_dim = 100  \nembedding_matrix = np.zeros((vocab_size, embedding_dim))\n\nfor word, i in tokenizer.word_index.items():\n    embedding_vector = embedding_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector\n\nprint(\"Embedding matrix shape:\", embedding_matrix.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T10:55:02.700124Z","iopub.execute_input":"2025-08-26T10:55:02.700656Z","iopub.status.idle":"2025-08-26T10:55:13.117919Z","shell.execute_reply.started":"2025-08-26T10:55:02.700632Z","shell.execute_reply":"2025-08-26T10:55:13.117260Z"}},"outputs":[{"name":"stdout","text":"Loaded GloVe word vectors: 400000\nEmbedding matrix shape: (13136, 100)\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"class AttentionLayer(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(AttentionLayer, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n                                 initializer=\"random_normal\", trainable=True)\n        self.b = self.add_weight(name=\"att_bias\", shape=(1,),\n                                 initializer=\"zeros\", trainable=True)\n        super(AttentionLayer, self).build(input_shape)\n\n    def call(self, x):\n        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n        a = tf.keras.backend.softmax(e, axis=1)\n        output = x * a\n        return tf.keras.backend.sum(output, axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T10:55:43.433221Z","iopub.execute_input":"2025-08-26T10:55:43.433443Z","iopub.status.idle":"2025-08-26T10:55:43.438840Z","shell.execute_reply.started":"2025-08-26T10:55:43.433427Z","shell.execute_reply":"2025-08-26T10:55:43.438157Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Embedding(\n    input_dim=vocab_size,\n    output_dim=embedding_dim,       \n    weights=[embedding_matrix],     \n    input_length=3,\n    trainable=False                 \n))\nmodel.add(LSTM(1000, return_sequences=True))  \nmodel.add(AttentionLayer())                   \nmodel.add(Dense(1000, activation=\"relu\"))\nmodel.add(Dense(vocab_size, activation=\"softmax\"))\nmodel.build(input_shape=(None, 3))\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T10:55:45.662624Z","iopub.execute_input":"2025-08-26T10:55:45.663176Z","iopub.status.idle":"2025-08-26T10:55:46.591535Z","shell.execute_reply.started":"2025-08-26T10:55:45.663156Z","shell.execute_reply":"2025-08-26T10:55:46.590993Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │     \u001b[38;5;34m1,313,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1000\u001b[0m)        │     \u001b[38;5;34m4,404,000\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ attention_layer                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │         \u001b[38;5;34m1,001\u001b[0m │\n│ (\u001b[38;5;33mAttentionLayer\u001b[0m)                │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │     \u001b[38;5;34m1,001,000\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13136\u001b[0m)          │    \u001b[38;5;34m13,149,136\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,404,000</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ attention_layer                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,001</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)                │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,001,000</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13136</span>)          │    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,149,136</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,868,737\u001b[0m (75.79 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,868,737</span> (75.79 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,555,137\u001b[0m (70.78 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,555,137</span> (70.78 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,313,600\u001b[0m (5.01 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,600</span> (5.01 MB)\n</pre>\n"},"metadata":{}}],"execution_count":26},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n\ncheckpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n\nearly_stop = EarlyStopping(\n    monitor='loss',  \n    patience=5,\n    restore_best_weights=True,\n    verbose=1\n)\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n\nmodel.fit(X, y, epochs=40, batch_size=64, callbacks=[checkpoint, early_stop])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T10:55:57.323817Z","iopub.execute_input":"2025-08-26T10:55:57.324458Z","iopub.status.idle":"2025-08-26T11:15:02.103047Z","shell.execute_reply.started":"2025-08-26T10:55:57.324435Z","shell.execute_reply":"2025-08-26T11:15:02.102418Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/40\n\u001b[1m1601/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.0142\nEpoch 1: loss improved from inf to 6.72205, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 17ms/step - loss: 7.0138\nEpoch 2/40\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.1193\nEpoch 2: loss improved from 6.72205 to 6.06944, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 6.1193\nEpoch 3/40\n\u001b[1m1601/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.6554\nEpoch 3: loss improved from 6.06944 to 5.61820, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 5.6554\nEpoch 4/40\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.2760\nEpoch 4: loss improved from 5.61820 to 5.25083, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 5.2760\nEpoch 5/40\n\u001b[1m1601/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.8971\nEpoch 5: loss improved from 5.25083 to 4.87408, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 4.8971\nEpoch 6/40\n\u001b[1m1601/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.4475\nEpoch 6: loss improved from 4.87408 to 4.44331, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 4.4475\nEpoch 7/40\n\u001b[1m1601/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.9300\nEpoch 7: loss improved from 4.44331 to 3.94544, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 3.9300\nEpoch 8/40\n\u001b[1m1599/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3875\nEpoch 8: loss improved from 3.94544 to 3.42837, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 3.3876\nEpoch 9/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8692\nEpoch 9: loss improved from 3.42837 to 2.92861, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 2.8693\nEpoch 10/40\n\u001b[1m1601/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.3900\nEpoch 10: loss improved from 2.92861 to 2.46154, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 2.3901\nEpoch 11/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9638\nEpoch 11: loss improved from 2.46154 to 2.04651, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 1.9640\nEpoch 12/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.6057\nEpoch 12: loss improved from 2.04651 to 1.70025, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 1.6058\nEpoch 13/40\n\u001b[1m1601/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3355\nEpoch 13: loss improved from 1.70025 to 1.43019, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 1.3356\nEpoch 14/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1365\nEpoch 14: loss improved from 1.43019 to 1.22381, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 1.1366\nEpoch 15/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.9853\nEpoch 15: loss improved from 1.22381 to 1.07297, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.9855\nEpoch 16/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8776\nEpoch 16: loss improved from 1.07297 to 0.95780, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 0.8777\nEpoch 17/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8059\nEpoch 17: loss improved from 0.95780 to 0.87571, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.8061\nEpoch 18/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7327\nEpoch 18: loss improved from 0.87571 to 0.81470, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.7329\nEpoch 19/40\n\u001b[1m1601/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6915\nEpoch 19: loss improved from 0.81470 to 0.76336, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 0.6916\nEpoch 20/40\n\u001b[1m1601/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6531\nEpoch 20: loss improved from 0.76336 to 0.72012, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.6532\nEpoch 21/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6294\nEpoch 21: loss improved from 0.72012 to 0.69398, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.6295\nEpoch 22/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5953\nEpoch 22: loss improved from 0.69398 to 0.66713, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.5954\nEpoch 23/40\n\u001b[1m1601/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5740\nEpoch 23: loss improved from 0.66713 to 0.64307, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.5741\nEpoch 24/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5549\nEpoch 24: loss improved from 0.64307 to 0.62581, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.5550\nEpoch 25/40\n\u001b[1m1599/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5552\nEpoch 25: loss improved from 0.62581 to 0.61342, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 0.5554\nEpoch 26/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5363\nEpoch 26: loss improved from 0.61342 to 0.59411, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 0.5364\nEpoch 27/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5203\nEpoch 27: loss improved from 0.59411 to 0.58190, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.5204\nEpoch 28/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5106\nEpoch 28: loss improved from 0.58190 to 0.56861, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 0.5107\nEpoch 29/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5036\nEpoch 29: loss improved from 0.56861 to 0.56076, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.5037\nEpoch 30/40\n\u001b[1m1601/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4919\nEpoch 30: loss improved from 0.56076 to 0.54911, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4920\nEpoch 31/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4891\nEpoch 31: loss improved from 0.54911 to 0.53919, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 0.4892\nEpoch 32/40\n\u001b[1m1601/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4788\nEpoch 32: loss improved from 0.53919 to 0.53592, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4788\nEpoch 33/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4692\nEpoch 33: loss improved from 0.53592 to 0.52432, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 0.4693\nEpoch 34/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4595\nEpoch 34: loss improved from 0.52432 to 0.51820, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4596\nEpoch 35/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4517\nEpoch 35: loss improved from 0.51820 to 0.51044, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4518\nEpoch 36/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4548\nEpoch 36: loss improved from 0.51044 to 0.50733, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 0.4549\nEpoch 37/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4530\nEpoch 37: loss improved from 0.50733 to 0.50531, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4531\nEpoch 38/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4437\nEpoch 38: loss improved from 0.50531 to 0.49362, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4438\nEpoch 39/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4407\nEpoch 39: loss improved from 0.49362 to 0.48995, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 0.4408\nEpoch 40/40\n\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4312\nEpoch 40: loss improved from 0.48995 to 0.48706, saving model to next_words.h5\n\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4313\nRestoring model weights from the end of the best epoch: 40.\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7a6fa2e01a90>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"def Predict_Next_Words_Beam(model, tokenizer, text, beam_width=3, next_words=5):\n\n    sequence = tokenizer.texts_to_sequences([text])[0]\n\n    beam = [(sequence, 0.0)]  \n\n    for _ in range(next_words):\n        candidates = []\n\n        for seq, score in beam:\n            seq_array = np.array(seq[-3:]).reshape(1, -1) \n            preds = model.predict(seq_array, verbose=0)[0]\n\n            top_indices = preds.argsort()[-beam_width:][::-1]\n\n            for idx in top_indices:\n                word = tokenizer.index_word[idx]\n                prob = np.log(preds[idx] + 1e-10)  \n                candidates.append((seq + [idx], score + prob))\n\n        beam = sorted(candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n\n    best_seq = beam[0][0]\n    predicted_words = [tokenizer.index_word[i] for i in best_seq[len(sequence):]]\n\n    print(f\"Predicted sequence: {' '.join(predicted_words)}\")\n    return predicted_words\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T11:15:05.720029Z","iopub.execute_input":"2025-08-26T11:15:05.720567Z","iopub.status.idle":"2025-08-26T11:15:05.726532Z","shell.execute_reply.started":"2025-08-26T11:15:05.720544Z","shell.execute_reply":"2025-08-26T11:15:05.725869Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"while True:\n    text = input(\"Enter your line: \")\n    \n    if text == \"0\":\n        print(\"Execution completed.....\")\n        break\n    else:\n        try:\n            text = text.split()[-3:]  \n            print(\"Input:\", text)\n            \n            Predict_Next_Words_Beam(model, tokenizer, text, beam_width=3, next_words=10)\n        except Exception as e:\n            print(\"Error occurred:\", e)\n            continue\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T12:01:08.884751Z","iopub.execute_input":"2025-08-26T12:01:08.885031Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter your line:  the project\n"},{"name":"stdout","text":"Input: ['the', 'project']\nPredicted sequence: gutenberg literary archive foundation royalty payments must be clearly marked\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import math\n\ndef calculate_perplexity(model, X, y, batch_size=512):\n    cross_entropy = 0.0\n    n_samples = 0\n    epsilon = 1e-10\n\n    for i in range(0, len(X), batch_size):\n        X_batch = X[i:i+batch_size]\n        y_batch = y[i:i+batch_size]\n\n        y_pred = model.predict(X_batch, verbose=0)\n        cross_entropy += -np.sum(y_batch * np.log(y_pred + epsilon))\n        n_samples += y_batch.shape[0]\n\n    cross_entropy /= n_samples\n    perplexity = math.exp(cross_entropy)\n    return cross_entropy, perplexity\n\ncross_entropy, perplexity = calculate_perplexity(model, X, y, batch_size=512)\nprint(\"Cross-entropy loss:\", cross_entropy)\nprint(\"Perplexity:\", perplexity)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T11:22:20.870951Z","iopub.execute_input":"2025-08-26T11:22:20.871630Z","iopub.status.idle":"2025-08-26T11:22:55.325524Z","shell.execute_reply.started":"2025-08-26T11:22:20.871606Z","shell.execute_reply":"2025-08-26T11:22:55.324820Z"}},"outputs":[{"name":"stdout","text":"Cross-entropy loss: 0.3820629202958525\nPerplexity: 1.4653042796112645\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nimport numpy as np\n\nsmoothie = SmoothingFunction().method4\n\ndef calculate_bleu_batch_verbose(model, tokenizer, X, y_true, batch_size=512, print_examples=10):\n    scores = []\n    examples_printed = 0\n\n    for i in range(0, len(X), batch_size):\n        X_batch = X[i:i+batch_size]\n        y_batch = y_true[i:i+batch_size]\n\n        y_pred_batch = model.predict(X_batch, verbose=0)\n\n        for j in range(len(X_batch)):\n            pred_index = np.argmax(y_pred_batch[j])\n            pred_word = tokenizer.index_word[pred_index]\n\n            true_index = np.argmax(y_batch[j])\n            true_word = tokenizer.index_word[true_index]\n\n            score = sentence_bleu([[true_word]], [pred_word], smoothing_function=smoothie)\n            scores.append(score)\n\n            if examples_printed < print_examples:\n                print(f\"Input sequence: {[tokenizer.index_word[idx] for idx in X_batch[j]]}\")\n                print(f\"Predicted next word: {pred_word} | Actual next word: {true_word}\\n\")\n                examples_printed += 1\n\n    return np.mean(scores)\n\nbleu_score_verbose = calculate_bleu_batch_verbose(model, tokenizer, X, y, batch_size=512, print_examples=10)\nprint(\"Average BLEU score:\", bleu_score_verbose)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T11:45:54.484097Z","iopub.execute_input":"2025-08-26T11:45:54.484415Z","iopub.status.idle":"2025-08-26T11:46:28.676099Z","shell.execute_reply.started":"2025-08-26T11:45:54.484393Z","shell.execute_reply":"2025-08-26T11:46:28.675435Z"}},"outputs":[{"name":"stdout","text":"Input sequence: ['project', \"gutenberg's\", 'the']\nPredicted next word: adventures | Actual next word: adventures\n\nInput sequence: [\"gutenberg's\", 'the', 'adventures']\nPredicted next word: of | Actual next word: of\n\nInput sequence: ['the', 'adventures', 'of']\nPredicted next word: sherlock | Actual next word: sherlock\n\nInput sequence: ['adventures', 'of', 'sherlock']\nPredicted next word: holmes | Actual next word: holmes\n\nInput sequence: ['of', 'sherlock', 'holmes']\nPredicted next word: by | Actual next word: by\n\nInput sequence: ['sherlock', 'holmes', 'by']\nPredicted next word: arthur | Actual next word: arthur\n\nInput sequence: ['holmes', 'by', 'arthur']\nPredicted next word: conan | Actual next word: conan\n\nInput sequence: ['by', 'arthur', 'conan']\nPredicted next word: doyle | Actual next word: doylethis\n\nInput sequence: ['arthur', 'conan', 'doylethis']\nPredicted next word: date | Actual next word: ebook\n\nInput sequence: ['conan', 'doylethis', 'ebook']\nPredicted next word: is | Actual next word: is\n\nAverage BLEU score: 0.8604639818933896\n","output_type":"stream"}],"execution_count":34}]}