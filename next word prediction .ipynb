{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-26T09:23:46.304738Z",
     "iopub.status.busy": "2025-08-26T09:23:46.304446Z",
     "iopub.status.idle": "2025-08-26T09:23:46.335232Z",
     "shell.execute_reply": "2025-08-26T09:23:46.334494Z",
     "shell.execute_reply.started": "2025-08-26T09:23:46.304717Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-26T09:23:46.304738Z",
     "iopub.status.busy": "2025-08-26T09:23:46.304446Z",
     "iopub.status.idle": "2025-08-26T09:23:46.335232Z",
     "shell.execute_reply": "2025-08-26T09:23:46.334494Z",
     "shell.execute_reply.started": "2025-08-26T09:23:46.304717Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan DoyleThis eBook is for the use of anyone anywhere at no cost and withalmost no restrictions whatsoever. You may copy it, give it away orre-use it under the terms of the Project Gutenberg License includedwith this eBook or online at www.gutenberg.netTitle: The Adventures of Sherlock HolmesAuthor: Arthur Conan DoyleRelease Date: November 29, 2002 [EBook #1661]Last Updated: May 20, 2019Language: EnglishCharacter set encoding: UT\n",
      "564156\n"
     ]
    }
   ],
   "source": [
    "file = open(\"/kaggle/input/next-word-prediction/1661-0.txt\", \"r\", encoding=\"utf8\")\n",
    "data = file.read()\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')\n",
    "data = ' '.join(data.split())\n",
    "print(data[:500])\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T09:23:57.716656Z",
     "iopub.status.busy": "2025-08-26T09:23:57.716331Z",
     "iopub.status.idle": "2025-08-26T09:23:57.899306Z",
     "shell.execute_reply": "2025-08-26T09:23:57.898637Z",
     "shell.execute_reply.started": "2025-08-26T09:23:57.716637Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159, 4841, 1, 956, 5, 122, 32, 44, 548, 2007, 4842, 1035, 13, 21, 1]\n",
      "102507\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "print(sequence_data[:15])\n",
    "print(len(sequence_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T09:24:00.218148Z",
     "iopub.status.busy": "2025-08-26T09:24:00.217871Z",
     "iopub.status.idle": "2025-08-26T09:24:01.038490Z",
     "shell.execute_reply": "2025-08-26T09:24:01.037671Z",
     "shell.execute_reply.started": "2025-08-26T09:24:00.218123Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13136\n",
      "The Length of sequences are:  102504\n",
      "[[ 159 4841    1  956]\n",
      " [4841    1  956    5]\n",
      " [   1  956    5  122]\n",
      " [ 956    5  122   32]\n",
      " [   5  122   32   44]\n",
      " [ 122   32   44  548]\n",
      " [  32   44  548 2007]\n",
      " [  44  548 2007 4842]\n",
      " [ 548 2007 4842 1035]\n",
      " [2007 4842 1035   13]]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)\n",
    "sequences = []\n",
    "\n",
    "for i in range(3, len(sequence_data)):\n",
    "    words = sequence_data[i-3:i+1]\n",
    "    sequences.append(words)\n",
    "    \n",
    "print(\"The Length of sequences are: \", len(sequences))\n",
    "sequences = np.array(sequences)\n",
    "print(sequences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T09:24:05.284409Z",
     "iopub.status.busy": "2025-08-26T09:24:05.283764Z",
     "iopub.status.idle": "2025-08-26T09:24:05.391145Z",
     "shell.execute_reply": "2025-08-26T09:24:05.390575Z",
     "shell.execute_reply.started": "2025-08-26T09:24:05.284360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in sequences:\n",
    "    X.append(i[0:3])\n",
    "    y.append(i[3])\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T09:24:08.134341Z",
     "iopub.status.busy": "2025-08-26T09:24:08.133521Z",
     "iopub.status.idle": "2025-08-26T09:24:08.139527Z",
     "shell.execute_reply": "2025-08-26T09:24:08.138723Z",
     "shell.execute_reply.started": "2025-08-26T09:24:08.134316Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  [[ 159 4841    1]\n",
      " [4841    1  956]\n",
      " [   1  956    5]\n",
      " [ 956    5  122]\n",
      " [   5  122   32]\n",
      " [ 122   32   44]\n",
      " [  32   44  548]\n",
      " [  44  548 2007]\n",
      " [ 548 2007 4842]\n",
      " [2007 4842 1035]]\n",
      "Response:  [ 956    5  122   32   44  548 2007 4842 1035   13]\n"
     ]
    }
   ],
   "source": [
    "print(\"Data: \", X[:10])\n",
    "print(\"Response: \", y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T09:24:11.317836Z",
     "iopub.status.busy": "2025-08-26T09:24:11.317589Z",
     "iopub.status.idle": "2025-08-26T09:24:11.630592Z",
     "shell.execute_reply": "2025-08-26T09:24:11.629890Z",
     "shell.execute_reply.started": "2025-08-26T09:24:11.317819Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T09:24:27.574409Z",
     "iopub.status.busy": "2025-08-26T09:24:27.573905Z",
     "iopub.status.idle": "2025-08-26T09:24:37.959142Z",
     "shell.execute_reply": "2025-08-26T09:24:37.958262Z",
     "shell.execute_reply.started": "2025-08-26T09:24:27.574369Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe word vectors: 400000\n",
      "Embedding matrix shape: (13136, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_index = {}\n",
    "glove_file = '/kaggle/input/glove-embeddings/glove.6B.100d.txt'  # path to your GloVe file\n",
    "\n",
    "with open(glove_file, 'r', encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embedding_index[word] = coefs\n",
    "\n",
    "print(\"Loaded GloVe word vectors:\", len(embedding_index))\n",
    "\n",
    "# Step 2: Create embedding matrix\n",
    "embedding_dim = 100  # based on GloVe file used\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(\"Embedding matrix shape:\", embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T09:26:35.699417Z",
     "iopub.status.busy": "2025-08-26T09:26:35.698574Z",
     "iopub.status.idle": "2025-08-26T09:26:35.704927Z",
     "shell.execute_reply": "2025-08-26T09:26:35.704207Z",
     "shell.execute_reply.started": "2025-08-26T09:26:35.699373Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"random_normal\", trainable=True)\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(1,),\n",
    "                                 initializer=\"zeros\", trainable=True)\n",
    "        super(AttentionLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = tf.keras.backend.tanh(tf.keras.backend.dot(x, self.W) + self.b)\n",
    "        a = tf.keras.backend.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "        return tf.keras.backend.sum(output, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T09:28:28.687780Z",
     "iopub.status.busy": "2025-08-26T09:28:28.687100Z",
     "iopub.status.idle": "2025-08-26T09:28:29.629882Z",
     "shell.execute_reply": "2025-08-26T09:28:29.629047Z",
     "shell.execute_reply.started": "2025-08-26T09:28:28.687755Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,404,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_layer                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,001</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AttentionLayer</span>)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1000</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,001,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13136</span>)          │    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,149,136</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m100\u001b[0m)         │     \u001b[38;5;34m1,313,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m1000\u001b[0m)        │     \u001b[38;5;34m4,404,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention_layer                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │         \u001b[38;5;34m1,001\u001b[0m │\n",
       "│ (\u001b[38;5;33mAttentionLayer\u001b[0m)                │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1000\u001b[0m)           │     \u001b[38;5;34m1,001,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13136\u001b[0m)          │    \u001b[38;5;34m13,149,136\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,868,737</span> (75.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,868,737\u001b[0m (75.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,555,137</span> (70.78 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,555,137\u001b[0m (70.78 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,313,600</span> (5.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,313,600\u001b[0m (5.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(\n",
    "    input_dim=vocab_size,\n",
    "    output_dim=embedding_dim,       \n",
    "    weights=[embedding_matrix],     \n",
    "    input_length=3,\n",
    "    trainable=False                 \n",
    "))\n",
    "model.add(LSTM(1000, return_sequences=True))  \n",
    "model.add(AttentionLayer())                   \n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))\n",
    "model.build(input_shape=(None, 3))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T09:29:01.593527Z",
     "iopub.status.busy": "2025-08-26T09:29:01.592746Z",
     "iopub.status.idle": "2025-08-26T09:53:04.921682Z",
     "shell.execute_reply": "2025-08-26T09:53:04.920654Z",
     "shell.execute_reply.started": "2025-08-26T09:29:01.593500Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 7.0087\n",
      "Epoch 1: loss improved from inf to 6.73303, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 18ms/step - loss: 7.0082\n",
      "Epoch 2/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 6.1134\n",
      "Epoch 2: loss improved from 6.73303 to 6.06280, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 6.1133\n",
      "Epoch 3/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.6334\n",
      "Epoch 3: loss improved from 6.06280 to 5.60157, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 5.6333\n",
      "Epoch 4/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.2522\n",
      "Epoch 4: loss improved from 5.60157 to 5.22371, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 5.2522\n",
      "Epoch 5/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.8596\n",
      "Epoch 5: loss improved from 5.22371 to 4.84573, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - loss: 4.8595\n",
      "Epoch 6/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 4.4168\n",
      "Epoch 6: loss improved from 4.84573 to 4.41022, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - loss: 4.4168\n",
      "Epoch 7/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.8992\n",
      "Epoch 7: loss improved from 4.41022 to 3.91147, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - loss: 3.8992\n",
      "Epoch 8/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 3.3615\n",
      "Epoch 8: loss improved from 3.91147 to 3.39334, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 3.3616\n",
      "Epoch 9/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.8371\n",
      "Epoch 9: loss improved from 3.39334 to 2.89319, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 2.8372\n",
      "Epoch 10/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.3585\n",
      "Epoch 10: loss improved from 2.89319 to 2.42831, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 2.3587\n",
      "Epoch 11/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.9298\n",
      "Epoch 11: loss improved from 2.42831 to 2.01767, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 1.9299\n",
      "Epoch 12/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.5778\n",
      "Epoch 12: loss improved from 2.01767 to 1.68032, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 1.5780\n",
      "Epoch 13/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.3280\n",
      "Epoch 13: loss improved from 1.68032 to 1.41458, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 1.3282\n",
      "Epoch 14/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1294\n",
      "Epoch 14: loss improved from 1.41458 to 1.21550, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 1.1296\n",
      "Epoch 15/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.9742\n",
      "Epoch 15: loss improved from 1.21550 to 1.06206, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.9743\n",
      "Epoch 16/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.8792\n",
      "Epoch 16: loss improved from 1.06206 to 0.95681, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.8793\n",
      "Epoch 17/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7811\n",
      "Epoch 17: loss improved from 0.95681 to 0.87595, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.7813\n",
      "Epoch 18/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.7313\n",
      "Epoch 18: loss improved from 0.87595 to 0.81082, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.7314\n",
      "Epoch 19/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6883\n",
      "Epoch 19: loss improved from 0.81082 to 0.76150, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.6885\n",
      "Epoch 20/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6447\n",
      "Epoch 20: loss improved from 0.76150 to 0.72259, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.6448\n",
      "Epoch 21/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.6313\n",
      "Epoch 21: loss improved from 0.72259 to 0.69750, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.6314\n",
      "Epoch 22/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5982\n",
      "Epoch 22: loss improved from 0.69750 to 0.66629, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.5984\n",
      "Epoch 23/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5807\n",
      "Epoch 23: loss improved from 0.66629 to 0.64412, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.5809\n",
      "Epoch 24/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5608\n",
      "Epoch 24: loss improved from 0.64412 to 0.62506, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.5609\n",
      "Epoch 25/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5474\n",
      "Epoch 25: loss improved from 0.62506 to 0.60816, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.5476\n",
      "Epoch 26/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5328\n",
      "Epoch 26: loss improved from 0.60816 to 0.59622, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.5329\n",
      "Epoch 27/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5291\n",
      "Epoch 27: loss improved from 0.59622 to 0.58285, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.5292\n",
      "Epoch 28/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5080\n",
      "Epoch 28: loss improved from 0.58285 to 0.56917, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.5081\n",
      "Epoch 29/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.5114\n",
      "Epoch 29: loss improved from 0.56917 to 0.56225, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.5115\n",
      "Epoch 30/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4931\n",
      "Epoch 30: loss improved from 0.56225 to 0.55568, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4933\n",
      "Epoch 31/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4906\n",
      "Epoch 31: loss improved from 0.55568 to 0.54249, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4907\n",
      "Epoch 32/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4830\n",
      "Epoch 32: loss improved from 0.54249 to 0.53551, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4831\n",
      "Epoch 33/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4767\n",
      "Epoch 33: loss improved from 0.53551 to 0.52435, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4768\n",
      "Epoch 34/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4656\n",
      "Epoch 34: loss improved from 0.52435 to 0.52007, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4657\n",
      "Epoch 35/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4649\n",
      "Epoch 35: loss improved from 0.52007 to 0.51605, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4650\n",
      "Epoch 36/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4617\n",
      "Epoch 36: loss improved from 0.51605 to 0.50760, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4618\n",
      "Epoch 37/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4495\n",
      "Epoch 37: loss improved from 0.50760 to 0.50469, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4496\n",
      "Epoch 38/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4412\n",
      "Epoch 38: loss improved from 0.50469 to 0.49902, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4413\n",
      "Epoch 39/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4422\n",
      "Epoch 39: loss improved from 0.49902 to 0.49273, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4423\n",
      "Epoch 40/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4444\n",
      "Epoch 40: loss improved from 0.49273 to 0.48864, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4445\n",
      "Epoch 41/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4422\n",
      "Epoch 41: loss improved from 0.48864 to 0.48394, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4423\n",
      "Epoch 42/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4266\n",
      "Epoch 42: loss improved from 0.48394 to 0.47429, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4267\n",
      "Epoch 43/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4302\n",
      "Epoch 43: loss did not improve from 0.47429\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 0.4303\n",
      "Epoch 44/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4359\n",
      "Epoch 44: loss did not improve from 0.47429\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 0.4360\n",
      "Epoch 45/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4129\n",
      "Epoch 45: loss improved from 0.47429 to 0.46710, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4130\n",
      "Epoch 46/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4123\n",
      "Epoch 46: loss improved from 0.46710 to 0.46065, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4123\n",
      "Epoch 47/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4176\n",
      "Epoch 47: loss did not improve from 0.46065\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 0.4177\n",
      "Epoch 48/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4167\n",
      "Epoch 48: loss improved from 0.46065 to 0.45949, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - loss: 0.4168\n",
      "Epoch 49/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4170\n",
      "Epoch 49: loss did not improve from 0.45949\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - loss: 0.4171\n",
      "Epoch 50/70\n",
      "\u001b[1m1600/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.4122\n",
      "Epoch 50: loss improved from 0.45949 to 0.45525, saving model to next_words.h5\n",
      "\u001b[1m1602/1602\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.4123\n",
      "Epoch 51/70\n",
      "\u001b[1m 220/1602\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - loss: 0.3647"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_194/90774815.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[1;32m    219\u001b[0m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/optional_ops.py\u001b[0m in \u001b[0;36mhas_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m       return gen_optional_ops.optional_has_value(\n\u001b[0m\u001b[1;32m    177\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m       )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_optional_ops.py\u001b[0m in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m    173\u001b[0m         _ctx, \"OptionalHasValue\", name, optional)\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='loss',  \n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "model.fit(X, y, epochs=70, batch_size=64, callbacks=[checkpoint, early_stop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T09:53:33.826263Z",
     "iopub.status.busy": "2025-08-26T09:53:33.825499Z",
     "iopub.status.idle": "2025-08-26T09:53:33.832694Z",
     "shell.execute_reply": "2025-08-26T09:53:33.831911Z",
     "shell.execute_reply.started": "2025-08-26T09:53:33.826239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def Predict_Next_Words_Beam(model, tokenizer, text, beam_width=3, next_words=5):\n",
    "\n",
    "    sequence = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "    beam = [(sequence, 0.0)]  \n",
    "\n",
    "    for _ in range(next_words):\n",
    "        candidates = []\n",
    "\n",
    "        for seq, score in beam:\n",
    "            seq_array = np.array(seq[-3:]).reshape(1, -1)  # keep last 3 words as per model input\n",
    "            preds = model.predict(seq_array, verbose=0)[0]\n",
    "\n",
    "            top_indices = preds.argsort()[-beam_width:][::-1]\n",
    "\n",
    "            for idx in top_indices:\n",
    "                word = tokenizer.index_word[idx]\n",
    "                prob = np.log(preds[idx] + 1e-10)  # log prob\n",
    "                candidates.append((seq + [idx], score + prob))\n",
    "\n",
    "        beam = sorted(candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "\n",
    "    best_seq = beam[0][0]\n",
    "    predicted_words = [tokenizer.index_word[i] for i in best_seq[len(sequence):]]\n",
    "\n",
    "    print(f\"Predicted sequence: {' '.join(predicted_words)}\")\n",
    "    return predicted_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T09:57:23.306637Z",
     "iopub.status.busy": "2025-08-26T09:57:23.306330Z",
     "iopub.status.idle": "2025-08-26T09:59:15.072904Z",
     "shell.execute_reply": "2025-08-26T09:59:15.071994Z",
     "shell.execute_reply.started": "2025-08-26T09:57:23.306616Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your line:  the project\n",
      "Input: ['the', 'project']\n",
      "Predicted sequence: gutenberg literary archive foundation was created to provide a secureand\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    text = input(\"Enter your line: \")\n",
    "    \n",
    "    if text == \"0\":\n",
    "        print(\"Execution completed.....\")\n",
    "        break\n",
    "    else:\n",
    "        try:\n",
    "            text = text.split()[-3:]  # last 3 words\n",
    "            print(\"Input:\", text)\n",
    "            \n",
    "            Predict_Next_Words_Beam(model, tokenizer, text, beam_width=3, next_words=10)\n",
    "        except Exception as e:\n",
    "            print(\"Error occurred:\", e)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-26T10:06:56.981627Z",
     "iopub.status.busy": "2025-08-26T10:06:56.980957Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "def calculate_perplexity(model, X, y_true, vocab_size):\n",
    "    y_onehot = to_categorical(y_true, num_classes=vocab_size)\n",
    "    loss = model.evaluate(X, y_onehot, verbose=0)\n",
    "    return np.exp(loss)\n",
    "\n",
    "def calculate_bleu(model, tokenizer, X, y_true):\n",
    "    preds = model.predict(X, verbose=0)\n",
    "    pred_indices = np.argmax(preds, axis=1)\n",
    "\n",
    "    smoothie = SmoothingFunction().method1\n",
    "    scores = []\n",
    "\n",
    "    for pred, true in zip(pred_indices, y_true):\n",
    "        if true in tokenizer.index_word:  \n",
    "            reference = [[tokenizer.index_word[true]]]  \n",
    "            hypothesis = [tokenizer.index_word.get(pred, \"\")]\n",
    "            score = sentence_bleu(reference, hypothesis,\n",
    "                                  smoothing_function=smoothie,\n",
    "                                  weights=(1, 0, 0, 0))\n",
    "            scores.append(score)\n",
    "\n",
    "    return np.mean(scores) if scores else 0.0\n",
    "\n",
    "\n",
    "def top_k_accuracy(model, X, y_true, k=5):\n",
    "    preds = model.predict(X, verbose=0)\n",
    "    top_k = np.argsort(preds, axis=1)[:, -k:]  \n",
    "    correct = sum(true in top_k[i] for i, true in enumerate(y_true))\n",
    "    return correct / len(y_true)\n",
    "\n",
    "y_int = np.argmax(y, axis=1) if y.ndim > 1 else y  \n",
    "\n",
    "perplexity = calculate_perplexity(model, X, y_int, vocab_size)\n",
    "bleu = calculate_bleu(model, tokenizer, X, y_int)\n",
    "top1 = top_k_accuracy(model, X, y_int, k=1)\n",
    "top5 = top_k_accuracy(model, X, y_int, k=5)\n",
    "\n",
    "print(f\"Perplexity: {perplexity:.4f}\")\n",
    "print(f\"BLEU-1 Score: {bleu:.4f}\")\n",
    "print(f\"Top-1 Accuracy: {top1:.4f}\")\n",
    "print(f\"Top-5 Accuracy: {top5:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2389252,
     "sourceId": 4032467,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 870709,
     "sourceId": 1483651,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
